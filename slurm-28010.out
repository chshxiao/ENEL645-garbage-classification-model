/home/chunsheng.xiao1/miniforge3/envs/pytorch/lib/python3.12/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
cuda:0
{0.0: 2111, 1.0: 4355, 2.0: 1991, 3.0: 1743}
['Black', 'Blue', 'Green', 'TTR']
Train set: 10208
Val set: 1824
Test set: 3456
/home/chunsheng.xiao1/miniforge3/envs/pytorch/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
torch.Size([32, 3, 256, 256])
torch.Size([32])
GarbageModel(
  (pretrained_model): VGG(
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU(inplace=True)
      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (6): ReLU(inplace=True)
      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (8): ReLU(inplace=True)
      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (11): ReLU(inplace=True)
      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (13): ReLU(inplace=True)
      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (15): ReLU(inplace=True)
      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (18): ReLU(inplace=True)
      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (20): ReLU(inplace=True)
      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (22): ReLU(inplace=True)
      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (25): ReLU(inplace=True)
      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (27): ReLU(inplace=True)
      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (29): ReLU(inplace=True)
      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
    (classifier): Sequential(
      (0): Linear(in_features=25088, out_features=4096, bias=True)
      (1): ReLU(inplace=True)
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=4096, out_features=4096, bias=True)
      (4): ReLU(inplace=True)
      (5): Dropout(p=0.5, inplace=False)
      (6): Linear(in_features=4096, out_features=1000, bias=True)
    )
  )
  (classifier): Linear(in_features=1000, out_features=4, bias=True)
)
Start training
1, ellapsed time: 395.8595926761627
train loss: 1.155, Accuracy of the network on the training images: 51.2539184952978 %
1, time ellapsed: 70.71701216697693
Validation loss: 1.203, Accuracy of the network on the validation images: 46.05263157894737 %
Saving model
2, ellapsed time: 392.66098642349243
train loss: 1.048, Accuracy of the network on the training images: 55.10384012539185 %
2, time ellapsed: 69.77680397033691
Validation loss: 0.999, Accuracy of the network on the validation images: 59.594298245614034 %
Saving model
3, ellapsed time: 388.4152286052704
train loss: 1.055, Accuracy of the network on the training images: 55.47609717868338 %
3, time ellapsed: 69.70638871192932
Validation loss: 1.088, Accuracy of the network on the validation images: 51.53508771929825 %
4, ellapsed time: 388.44086837768555
train loss: 1.032, Accuracy of the network on the training images: 56.36755485893417 %
4, time ellapsed: 69.4824321269989
Validation loss: 0.997, Accuracy of the network on the validation images: 59.53947368421053 %
5, ellapsed time: 387.80044651031494
train loss: 1.003, Accuracy of the network on the training images: 57.67045454545455 %
5, time ellapsed: 69.48961162567139
Validation loss: 1.006, Accuracy of the network on the validation images: 57.45614035087719 %
6, ellapsed time: 389.00587582588196
train loss: 1.008, Accuracy of the network on the training images: 56.4557210031348 %
6, time ellapsed: 69.56826210021973
Validation loss: 1.117, Accuracy of the network on the validation images: 50.0 %
7, ellapsed time: 389.58618688583374
train loss: 0.983, Accuracy of the network on the training images: 57.072884012539184 %
7, time ellapsed: 69.94741177558899
Validation loss: 1.036, Accuracy of the network on the validation images: 54.824561403508774 %
8, ellapsed time: 390.75988936424255
train loss: 0.964, Accuracy of the network on the training images: 58.52272727272727 %
8, time ellapsed: 69.93745827674866
Validation loss: 1.028, Accuracy of the network on the validation images: 54.76973684210526 %
9, ellapsed time: 390.1498863697052
train loss: 0.965, Accuracy of the network on the training images: 58.424764890282134 %
9, time ellapsed: 69.73006010055542
Validation loss: 0.992, Accuracy of the network on the validation images: 57.45614035087719 %
10, ellapsed time: 389.80764865875244
train loss: 0.945, Accuracy of the network on the training images: 59.629702194357364 %
10, time ellapsed: 70.25736546516418
Validation loss: 1.056, Accuracy of the network on the validation images: 54.93421052631579 %
11, ellapsed time: 389.019150018692
train loss: 0.943, Accuracy of the network on the training images: 59.52194357366771 %
11, time ellapsed: 69.75658965110779
Validation loss: 1.066, Accuracy of the network on the validation images: 52.57675438596491 %
12, ellapsed time: 389.64577412605286
train loss: 0.933, Accuracy of the network on the training images: 59.198667711598745 %
12, time ellapsed: 69.55069065093994
Validation loss: 1.004, Accuracy of the network on the validation images: 55.53728070175438 %
13, ellapsed time: 390.5981225967407
train loss: 0.935, Accuracy of the network on the training images: 59.414184952978054 %
13, time ellapsed: 69.69703125953674
Validation loss: 0.942, Accuracy of the network on the validation images: 58.44298245614035 %
14, ellapsed time: 389.44910764694214
train loss: 0.934, Accuracy of the network on the training images: 59.61990595611285 %
14, time ellapsed: 69.54599666595459
Validation loss: 0.956, Accuracy of the network on the validation images: 58.771929824561404 %
15, ellapsed time: 390.0411202907562
train loss: 0.917, Accuracy of the network on the training images: 60.0705329153605 %
15, time ellapsed: 69.80389428138733
Validation loss: 0.997, Accuracy of the network on the validation images: 56.79824561403509 %
1, ellapsed time: 414.8394773006439
train loss: 0.871, Accuracy of the network on the training images: 62.98001567398119 %
1, time ellapsed: 70.07096314430237
Validation loss: 0.897, Accuracy of the network on the validation images: 61.40350877192982 %
Saving model
2, ellapsed time: 416.3832576274872
train loss: 0.825, Accuracy of the network on the training images: 64.89028213166144 %
2, time ellapsed: 69.83054423332214
Validation loss: 0.864, Accuracy of the network on the validation images: 62.77412280701754 %
Saving model
3, ellapsed time: 417.3960671424866
train loss: 0.798, Accuracy of the network on the training images: 65.67398119122257 %
3, time ellapsed: 70.09674382209778
Validation loss: 0.844, Accuracy of the network on the validation images: 63.70614035087719 %
Saving model
4, ellapsed time: 416.26157546043396
train loss: 0.779, Accuracy of the network on the training images: 67.52547021943573 %
4, time ellapsed: 70.3289999961853
Validation loss: 0.818, Accuracy of the network on the validation images: 65.625 %
Saving model
5, ellapsed time: 416.64547061920166
train loss: 0.760, Accuracy of the network on the training images: 67.96630094043887 %
5, time ellapsed: 69.82146549224854
Validation loss: 0.842, Accuracy of the network on the validation images: 64.69298245614036 %

Finished traning
Traceback (most recent call last):
  File "/home/chunsheng.xiao1/miniforge3/envs/pytorch/lib/python3.12/site-packages/torch/serialization.py", line 531, in _check_seekable
    f.seek(f.tell())
    ^^^^^^
AttributeError: 'DataLoader' object has no attribute 'seek'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/chunsheng.xiao1/assignment2/garbage_classification_main.py", line 141, in <module>
    labels_test, predict_test = image_model_predict(image_model_test, img_test_loader, test_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/chunsheng.xiao1/assignment2/image_model.py", line 263, in image_model_predict
    
  File "/home/chunsheng.xiao1/miniforge3/envs/pytorch/lib/python3.12/site-packages/torch/serialization.py", line 986, in load
    with _open_file_like(f, 'rb') as opened_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/chunsheng.xiao1/miniforge3/envs/pytorch/lib/python3.12/site-packages/torch/serialization.py", line 440, in _open_file_like
    return _open_buffer_reader(name_or_buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/chunsheng.xiao1/miniforge3/envs/pytorch/lib/python3.12/site-packages/torch/serialization.py", line 425, in __init__
    _check_seekable(buffer)
  File "/home/chunsheng.xiao1/miniforge3/envs/pytorch/lib/python3.12/site-packages/torch/serialization.py", line 534, in _check_seekable
    raise_err_msg(["seek", "tell"], e)
  File "/home/chunsheng.xiao1/miniforge3/envs/pytorch/lib/python3.12/site-packages/torch/serialization.py", line 527, in raise_err_msg
    raise type(e)(msg)
AttributeError: 'DataLoader' object has no attribute 'seek'. You can only torch.load from a file that is seekable. Please pre-load the data into a buffer like io.BytesIO and try to load from it instead.
